# -*- coding: utf-8 -*-
"""ID_Lab_Scrape_Tariff_to_csv.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15mwNxgasVS4FJYMA4g1ZoFuhjBpT_dW9
"""

# Installing libraries
!pip install PyPDF2
!pip install pdfplumber

import pdfplumber
import pandas as pd
import re
import os

def extract_text_and_tables(pdf_file):
    # Read the PDF file
    with pdfplumber.open(pdf_file) as pdf:
        # Initialize variables
        tables = []
        table_texts = []

        # Iterate through each page
        for i, page in enumerate(pdf.pages):
            # Extract tables
            page_tables = page.extract_tables()

            # Extract text
            raw_text = page.extract_text()

            # Find text above tables
            for table in page_tables:
                for row in table:
                    first_cell = row[0] if row[0] is not None else ''
                    # Look for the text above the table
                    match = re.search(r'(.*)\n'+re.escape(first_cell), raw_text)
                    if match:
                        table_text = match.group(1)
                        break
                    else:
                        table_text = ''

                # Clean table by removing None values and replacing with empty strings
                cleaned_table = [[cell if cell is not None else '' for cell in row] for row in table]

                # Add table and its text
                tables.append(pd.DataFrame(cleaned_table))
                table_texts.append(table_text)

    return tables, table_texts

def save_tables_to_csv(tables, table_texts, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for i, (table_text, table) in enumerate(zip(table_texts, tables)):
        # Insert the text above the table as a separate row on top of the table
        text_row = pd.DataFrame([[table_text] + [''] * (table.shape[1] - 1)], columns=table.columns)
        output_table = pd.concat([text_row, table], ignore_index=True)

        # Save the table to a CSV file
        output_file = os.path.join(output_folder, f'table_{i+1}.csv')
        output_table.to_csv(output_file, index=False)

# Replace with your PDF file
pdf_file = '/content/UGVCL1911-2020-Tariff-Order-for-FY-2021-22-dtd.31.03.2021.pdf'
output_folder = '/content/example.csv'

tables, table_texts = extract_text_and_tables(pdf_file)
save_tables_to_csv(tables, table_texts, output_folder)

# Income Dynamics Lab - import the necessary libraries
import pdfplumber
import pandas as pd
import re
import os

# This script will scrape PDFs from tables
def extract_text_and_tables(pdf_file):
    # Read the PDF file
    with pdfplumber.open(pdf_file) as pdf:
        # Initialize variables
        tables = []
        table_texts = []

        # Iterate through each page
        for i, page in enumerate(pdf.pages):
            # Extract tables
            page_tables = page.extract_tables()

            # Extract text
            raw_text = page.extract_text()

            # Find text above tables
            for table in page_tables:
                for row in table:
                    first_cell = row[0] if row[0] is not None else ''
                    # Look for the text above the table
                    match = re.search(r'(.*)\n'+re.escape(first_cell), raw_text)
                    if match:
                        table_text = match.group(1)
                        break
                    else:
                        table_text = ''

                # Check if the word "tariff" is written above the table or in the table
                if 'tariff' in table_text.lower() or any('tariff' in cell.lower() for row in table for cell in row if cell is not None):
                    # Clean table by removing None values and replacing with empty strings
                    cleaned_table = [[cell if cell is not None else '' for cell in row] for row in table]

                    # Add table and its text
                    tables.append(pd.DataFrame(cleaned_table))
                    table_texts.append(table_text)

    return tables, table_texts

def save_tables_to_csv(tables, table_texts, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for i, (table_text, table) in enumerate(zip(table_texts, tables)):
        # Insert the text above the table as a separate row on top of the table
        text_row = pd.DataFrame([[table_text] + [''] * (table.shape[1] - 1)], columns=table.columns)
        output_table = pd.concat([text_row, table], ignore_index=True)

        # Save the table to a CSV file
        output_file = os.path.join(output_folder, f'tariff_table_{i+1}.csv')
        output_table.to_csv(output_file, index=False)

# Replace with your PDF file
pdf_file = '/content/UGVCL1911-2020-Tariff-Order-for-FY-2021-22-dtd.31.03.2021.pdf'
output_folder = '/content/example.csv'

tables, table_texts = extract_text_and_tables(pdf_file)
save_tables_to_csv(tables, table_texts, output_folder)

import pdfplumber
import pandas as pd
import re
import os

def extract_text_and_tables(pdf_file):
    # Read the PDF file
    with pdfplumber.open(pdf_file) as pdf:
        # Initialize variables
        tables = []
        table_info = []

        # Iterate through each page
        for i, page in enumerate(pdf.pages):
            # Extract tables
            page_tables = page.extract_tables()

            # Extract text
            raw_text = page.extract_text()

            # Extract page number
            page_number_match = re.search(r'page (\d+)', raw_text.lower())
            if page_number_match:
                page_number = int(page_number_match.group(1))
            else:
                page_number = i + 1

            # Find text above tables
            for table in page_tables:
                for row in table:
                    first_cell = row[0] if row[0] is not None else ''
                    match = re.search(r'(.*)\n'+re.escape(first_cell), raw_text)
                    if match:
                        table_text = match.group(1)
                        break
                    else:
                        table_text = ''

                if 'tariff' in table_text.lower() or any('tariff' in cell.lower() for row in table for cell in row if cell is not None):
                    cleaned_table = [[cell if cell is not None else '' for cell in row] for row in table]
                    tables.append(pd.DataFrame(cleaned_table))
                    table_info.append((table_text, page_number))

    return tables, table_info

def save_tables_to_csv(tables, table_info, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for i, (info, table) in enumerate(zip(table_info, tables)):
        table_text, page_number = info
        text_row = pd.DataFrame([[table_text] + [''] * (table.shape[1] - 1)], columns=table.columns)
        page_row = pd.DataFrame([['Page', page_number] + [''] * (table.shape[1] - 2)], columns=table.columns)
        output_table = pd.concat([page_row, text_row, table], ignore_index=True)

        output_file = os.path.join(output_folder, f'tariff_table_{i+1}.csv')
        output_table.to_csv(output_file, index=False)

pdf_file = '/content/UGVCL1911-2020-Tariff-Order-for-FY-2021-22-dtd.31.03.2021.pdf'
output_folder = '/content/example.csv'

tables, table_info = extract_text_and_tables(pdf_file)
save_tables_to_csv(tables, table_info, output_folder)

import pdfplumber
import pandas as pd
import re
import os

def extract_text_and_tables(pdf_file):
    # Read the PDF file
    with pdfplumber.open(pdf_file) as pdf:
        # Initialize variables
        tables = []
        table_info = []

        # Iterate through each page
        for i, page in enumerate(pdf.pages):
            # Extract tables
            page_tables = page.extract_tables()

            # Extract text
            raw_text = page.extract_text()

            # Extract page number
            page_number_match = re.search(r'page (\d+)', raw_text.lower())
            if page_number_match:
                page_number = int(page_number_match.group(1))
            else:
                page_number = i + 1

            # Find text above tables
            for table in page_tables:
                for row in table:
                    first_cell = row[0] if row[0] is not None else ''
                    match = re.search(r'(.*)\n'+re.escape(first_cell), raw_text)
                    if match:
                        table_text = match.group(1)
                        break
                    else:
                        table_text = ''

                # Check if the word "tariff" is written above the table or in the table and either "commercial" or "agricultural"
                if 'tariff' in table_text.lower() or any('tariff' in cell.lower() for row in table for cell in row if cell is not None):
                    if 'commercial' in table_text.lower() or 'agricultural' in table_text.lower() or any('commercial' in cell.lower() or 'agricultural' in cell.lower() for row in table for cell in row if cell is not None):
                        cleaned_table = [[cell if cell is not None else '' for cell in row] for row in table]
                        tables.append(pd.DataFrame(cleaned_table))
                        table_info.append((table_text, page_number))

    return tables, table_info

def save_tables_to_csv(tables, table_info, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for i, (info, table) in enumerate(zip(table_info, tables)):
        table_text, page_number = info
        text_row = pd.DataFrame([[table_text] + [''] * (table.shape[1] - 1)], columns=table.columns)
        page_row = pd.DataFrame([['Page', page_number] + [''] * (table.shape[1] - 2)], columns=table.columns)
        output_table = pd.concat([page_row, text_row, table], ignore_index=True)

        output_file = os.path.join(output_folder, f'tariff_table_{i+1}.csv')
        output_table.to_csv(output_file, index=False)

pdf_file = '/content/UGVCL1911-2020-Tariff-Order-for-FY-2021-22-dtd.31.03.2021.pdf'
output_folder = '/content/example.csv'

tables, table_info = extract_text_and_tables(pdf_file)
save_tables_to_csv(tables, table_info, output_folder)

# 2nd attempt at the optional keywords
import pdfplumber
import pandas as pd
import re
import os

def extract_text_and_tables(pdf_file, optional_keywords):
    # Read the PDF file
    with pdfplumber.open(pdf_file) as pdf:
        # Initialize variables
        tables = []
        table_info = []

        # Iterate through each page
        for i, page in enumerate(pdf.pages):
            # Extract tables
            page_tables = page.extract_tables()

            # Extract text
            raw_text = page.extract_text()

            # Extract page number
            page_number_match = re.search(r'page (\d+)', raw_text.lower())
            if page_number_match:
                page_number = int(page_number_match.group(1))
            else:
                page_number = i + 1

            # Find text above tables
            for table in page_tables:
                for row in table:
                    first_cell = row[0] if row[0] is not None else ''
                    match = re.search(r'(.*)\n'+re.escape(first_cell), raw_text)
                    if match:
                        table_text = match.group(1)
                        break
                    else:
                        table_text = ''

                # Check if the word "tariff" is written above the table or in the table and any of the optional keywords
                if 'tariff' in table_text.lower() or any('tariff' in cell.lower() for row in table for cell in row if cell is not None):
                    if any(keyword in table_text.lower() or any(keyword in cell.lower() for row in table for cell in row if cell is not None) for keyword in optional_keywords):
                        cleaned_table = [[cell if cell is not None else '' for cell in row] for row in table]
                        tables.append(pd.DataFrame(cleaned_table))
                        table_info.append((table_text, page_number))

    return tables, table_info

def save_tables_to_csv(tables, table_info, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for i, (info, table) in enumerate(zip(table_info, tables)):
        table_text, page_number = info
        text_row = pd.DataFrame([[table_text] + [''] * (table.shape[1] - 1)], columns=table.columns)
        page_row = pd.DataFrame([['Page', page_number] + [''] * (table.shape[1] - 2)], columns=table.columns)
        output_table = pd.concat([page_row, text_row, table], ignore_index=True)

        output_file = os.path.join(output_folder, f'tariff_table_{i+1}.csv')
        output_table.to_csv(output_file, index=False)


pdf_file = '/content/UGVCL1911-2020-Tariff-Order-for-FY-2021-22-dtd.31.03.2021.pdf'
output_folder = '/content/example.csv'
optional_keywords = []  # Add or remove keywords as needed

tables, table_info = extract_text_and_tables(pdf_file, optional_keywords)
save_tables_to_csv(tables, table_info, output_folder)

# hopefully handle empty optional keywords

import pdfplumber
import pandas as pd
import re
import os

def extract_text_and_tables(pdf_file, optional_keywords):
    # Read the PDF file
    with pdfplumber.open(pdf_file) as pdf:
        # Initialize variables
        tables = []
        table_info = []

        # Iterate through each page
        for i, page in enumerate(pdf.pages):
            # Extract tables
            page_tables = page.extract_tables()

            # Extract text
            raw_text = page.extract_text()

            # Extract page number
            page_number_match = re.search(r'page (\d+)', raw_text.lower())
            if page_number_match:
                page_number = int(page_number_match.group(1))
            else:
                page_number = i + 1

            # Find text above tables
            for table in page_tables:
                for row in table:
                    first_cell = row[0] if row[0] is not None else ''
                    match = re.search(r'(.*)\n'+re.escape(first_cell), raw_text)
                    if match:
                        table_text = match.group(1)
                        break
                    else:
                        table_text = ''

                # Check if the word "tariff" is written above the table or in the table and any of the optional keywords
                if 'tariff' in table_text.lower() or any('tariff' in cell.lower() for row in table for cell in row if cell is not None):
                    if not optional_keywords or any(keyword in table_text.lower() or any(keyword in cell.lower() for row in table for cell in row if cell is not None) for keyword in optional_keywords):
                        cleaned_table = [[cell if cell is not None else '' for cell in row] for row in table]
                        tables.append(pd.DataFrame(cleaned_table))
                        table_info.append((table_text, page_number))

    return tables, table_info

def save_tables_to_csv(tables, table_info, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for i, (info, table) in enumerate(zip(table_info, tables)):
        table_text, page_number = info
        text_row = pd.DataFrame([[table_text] + [''] * (table.shape[1] - 1)], columns=table.columns)
        page_row = pd.DataFrame([['Page', page_number] + [''] * (table.shape[1] - 2)], columns=table.columns)
        output_table = pd.concat([page_row, text_row, table], ignore_index=True)

        output_file = os.path.join(output_folder, f'tariff_table_{i+1}.csv')
        output_table.to_csv(output_file, index=False)

pdf_file = '/content/UGVCL1911-2020-Tariff-Order-for-FY-2021-22-dtd.31.03.2021.pdf'
output_folder = '/content/example.csv'
optional_keywords = ['AG', 'C&I', 'Agriculture', 'Commercial']  # The list is empty now, but you can add or remove keywords as needed

tables, table_info = extract_text_and_tables(pdf_file, optional_keywords)
save_tables_to_csv(tables, table_info, output_folder)

# Attempt at OCR code
import pdfplumber
import pytesseract
import pandas as pd
import re
import os

def extract_text_and_tables_ocr(pdf_file, optional_keywords):
    # Read the PDF file
    with pdfplumber.open(pdf_file) as pdf:
        # Initialize variables
        tables = []
        table_info = []

        # Iterate through each page
        for i, page in enumerate(pdf.pages):
            # Perform OCR on the page
            im = page.to_image(resolution=300)
            raw_text = pytesseract.image_to_string(im.original)

            # Extract tables
            page_tables = page.extract_tables()

            # Extract page number
            page_number_match = re.search(r'page (\d+)', raw_text.lower())
            if page_number_match:
                page_number = int(page_number_match.group(1))
            else:
                page_number = i + 1

            # Find text above tables
            for table in page_tables:
                for row in table:
                    first_cell = row[0] if row[0] is not None else ''
                    match = re.search(r'(.*)\n'+re.escape(first_cell), raw_text)
                    if match:
                        table_text = match.group(1)
                        break
                    else:
                        table_text = ''

                # Check if the word "tariff" is written above the table or in the table and any of the optional keywords
                if 'tariff' in table_text.lower() or any('tariff' in cell.lower() for row in table for cell in row if cell is not None):
                    if any(keyword in table_text.lower() or any(keyword in cell.lower() for row in table for cell in row if cell is not None) for keyword in optional_keywords):
                        cleaned_table = [[cell if cell is not None else '' for cell in row] for row in table]
                        tables.append(pd.DataFrame(cleaned_table))
                        table_info.append((table_text, page_number))

    return tables, table_info

def save_tables_to_csv(tables, table_info, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for i, (info, table) in enumerate(zip(table_info, tables)):
        table_text, page_number = info
        text_row = pd.DataFrame([[table_text] + [''] * (table.shape[1] - 1)], columns=table.columns)
        page_row = pd.DataFrame([['Page', page_number] + [''] * (table.shape[1] - 2)], columns=table.columns)
        output_table = pd.concat([page_row, text_row, table], ignore_index=True)

        output_file = os.path.join(output_folder, f'tariff_table_{i+1}.csv')
        output_table.to_csv(output_file, index=False)

pdf_file = 'path/to/your/pdf_file.pdf'
output_folder = 'output_tariff_tables_ocr'
optional_keywords = ['commercial', 'agricultural']  # Add or remove keywords as needed

tables, table_info = extract_text_and_tables_ocr(pdf_file, optional_keywords)
save_tables_to_csv(tables, table_info, output_folder)

!zip -r /content/tariffcsv.zip /content/example.csv

from google.colab import files
files.download("/content/tariffcsv.zip")